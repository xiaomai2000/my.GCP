{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f459cc1b",
   "metadata": {},
   "source": [
    "### Machine learning by Spark in Dataproc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b546376f",
   "metadata": {},
   "source": [
    "from https://www.cloudskillsboost.google/focuses/3390?locale=en&parent=catalog\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798a12a8",
   "metadata": {},
   "source": [
    "Apache Spark is an analytics engine for large scale data processing. Logistic regression is available as a module in Apache Spark's machine learning library, MLlib. Spark MLlib, also called Spark ML, includes implementations for most standard machine learning algorithms such as k-means clustering, random forests, alternating least squares, k-means clustering, decision trees, support vector machines, etc. Spark can run on a Hadoop cluster, like Dataproc, in order to process very large datasets in parallel."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab5ff65",
   "metadata": {},
   "source": [
    "The base dataset this lab uses is retrieved from the US Bureau of Transport Statistics. The dataset provides historical information about internal flights in the United States and can be used to demonstrate a wide range of data science concepts and techniques. This lab provides the data as a set of CSV formatted text files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef5205c",
   "metadata": {},
   "source": [
    "Note: you need to create a storage bucket \"my-project-1011-1012-dsongcp\" as this was not mentioned in the guide book.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1acfba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT = !gcloud config get-value project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78570e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT=PROJECT[0]\n",
    "BUCKET = PROJECT + '-dsongcp'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca43dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['BUCKET'] = PROJECT + '-dsongcp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ba389f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c31a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7a2ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext('local', 'logistic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafc3380",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName('Logistic regression w/ Spark ML') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72652370",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.classification import LogisticRegressionWithLBFGS\n",
    "from pyspark.mllib.regression import LabeledPoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe120a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#traindays = spark.read.option(\"header\", \"true\").csv('gs://{}/flights/trainday.csv'.format(BUCKET))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
