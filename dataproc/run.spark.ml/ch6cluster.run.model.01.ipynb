{"cells": [{"cell_type": "code", "execution_count": 2, "id": "6dfe1b3c-bb19-4749-be76-0a0127108191", "metadata": {}, "outputs": [], "source": "PROJECT = !gcloud config get-value project"}, {"cell_type": "code", "execution_count": 3, "id": "285ffdd9-4b54-43fe-b37d-8295573d680b", "metadata": {}, "outputs": [], "source": "PROJECT=PROJECT[0]\nBUCKET = PROJECT + '-dsongcp'"}, {"cell_type": "code", "execution_count": 4, "id": "63a7e9c6-77ac-4048-ba8a-b59b54b47bcc", "metadata": {}, "outputs": [], "source": "import os\nos.environ['BUCKET'] = PROJECT + '-dsongcp'"}, {"cell_type": "code", "execution_count": 5, "id": "ac8ee174-97a4-4c50-90d7-5df62ba26aa5", "metadata": {}, "outputs": [], "source": "from pyspark.sql import SparkSession"}, {"cell_type": "code", "execution_count": 6, "id": "ba8fccc6-6ec1-47e2-8aae-68ed20e3e7cf", "metadata": {}, "outputs": [], "source": "from pyspark import SparkContext"}, {"cell_type": "code", "execution_count": 7, "id": "1a46d580-50f7-4b7a-8cc4-992f49bde846", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "Setting default log level to \"WARN\".\nTo adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n22/11/17 15:12:44 INFO org.apache.spark.SparkEnv: Registering MapOutputTracker\n22/11/17 15:12:44 INFO org.apache.spark.SparkEnv: Registering BlockManagerMaster\n22/11/17 15:12:44 INFO org.apache.spark.SparkEnv: Registering BlockManagerMasterHeartbeat\n22/11/17 15:12:44 INFO org.apache.spark.SparkEnv: Registering OutputCommitCoordinator\n"}], "source": "sc = SparkContext('local', 'logistic')"}, {"cell_type": "code", "execution_count": 8, "id": "4ad231a7-d94d-4104-b90e-3685dbcb2418", "metadata": {}, "outputs": [], "source": "spark = SparkSession \\\n    .builder \\\n    .appName('Logistic regression w/ Spark ML') \\\n    .getOrCreate()"}, {"cell_type": "code", "execution_count": 9, "id": "62f2db08-56ce-4d7f-9aec-1dfe4d52fad1", "metadata": {}, "outputs": [], "source": "from pyspark import SparkContext\nfrom pyspark.mllib.classification import LogisticRegressionWithLBFGS, LogisticRegressionModel\nfrom pyspark.mllib.regression import LabeledPoint"}, {"cell_type": "code", "execution_count": 10, "id": "42eebfdc-84ae-4e77-aeb6-41659cb2c5b3", "metadata": {}, "outputs": [], "source": "# Load and parse the data\ndef parsePoint(line):\n    values = [float(x) for x in line.split(' ')]\n    return LabeledPoint(values[0], values[1:])"}, {"cell_type": "code", "execution_count": 11, "id": "aa8ec0b9-24f4-46e1-a755-ca86f0574c3b", "metadata": {}, "outputs": [], "source": "data = sc.textFile('gs://{}/spark/sample_svm_data.txt'.format(BUCKET))\n"}, {"cell_type": "code", "execution_count": 12, "id": "43ef90b9-1f3d-4048-84e6-b7b1962a877c", "metadata": {}, "outputs": [], "source": "parsedData = data.map(parsePoint)"}, {"cell_type": "code", "execution_count": 13, "id": "60bfa1c6-8a95-4c7f-825a-02017898dc38", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "22/11/17 15:12:56 WARN org.apache.hadoop.util.concurrent.ExecutorHelper: Thread (Thread[GetFileInfo #1,5,main]) interrupted: \njava.lang.InterruptedException\n\tat com.google.common.util.concurrent.AbstractFuture.get(AbstractFuture.java:510)\n\tat com.google.common.util.concurrent.FluentFuture$TrustedFuture.get(FluentFuture.java:88)\n\tat org.apache.hadoop.util.concurrent.ExecutorHelper.logThrowableFromAfterExecute(ExecutorHelper.java:48)\n\tat org.apache.hadoop.util.concurrent.HadoopThreadPoolExecutor.afterExecute(HadoopThreadPoolExecutor.java:90)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1157)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\n22/11/17 15:13:04 WARN org.apache.spark.ml.util.Instrumentation: [0df419c1] Initial coefficients will be ignored! Its dimensions (1, 16) did not match the expected size (1, 16)\n22/11/17 15:13:05 WARN com.github.fommil.netlib.BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS\n22/11/17 15:13:05 WARN com.github.fommil.netlib.BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS\n"}], "source": "# Build the model\nmodel = LogisticRegressionWithLBFGS.train(parsedData)"}, {"cell_type": "code", "execution_count": 14, "id": "7c0c5d0b-42a9-4291-919e-559477c1e153", "metadata": {}, "outputs": [], "source": "# Evaluating the model on training data\nlabelsAndPreds = parsedData.map(lambda p: (p.label, model.predict(p.features)))"}, {"cell_type": "code", "execution_count": 15, "id": "c82e0266-0a72-41a8-a849-fd61974b3b62", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Training Error = 0.36645962732919257\n"}], "source": "trainErr = labelsAndPreds.filter(lambda lp: lp[0] != lp[1]).count() / float(parsedData.count())\nprint(\"Training Error = \" + str(trainErr))"}, {"cell_type": "code", "execution_count": null, "id": "7f77a7dd-5089-4744-a258-dd95fe4b7838", "metadata": {}, "outputs": [], "source": ""}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8.13"}}, "nbformat": 4, "nbformat_minor": 5}